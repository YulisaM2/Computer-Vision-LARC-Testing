{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from model.yolo_model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping image (resize, reduce and expanding it)\n",
    "def process_image(img):\n",
    "    image = cv2.resize(img, (416, 416),\n",
    "                       interpolation=cv2.INTER_CUBIC)\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image /= 255.\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting class name from the coco dataset (.txt)\n",
    "def get_classes(file):\n",
    "    with open(file) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing the boudary boxes on image\n",
    "def draw(image,boxes,scores,classes,all_classes):\n",
    "    for box, score, cl in zip(boxes, scores, classes):\n",
    "        x,y,w,h = box\n",
    "        \n",
    "        top = max(0,np.floor(x + 0.5).astype(int))\n",
    "        left = max(0,np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1],np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0],np.floor(y + h + 0.5).astype(int))\n",
    "        \n",
    "        cv2.rectangle(image, (top,left), (right,bottom) ,(255,0,0), 2)\n",
    "        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl],score),(top,left - 6),cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255),1,cv2.LINE_AA)\n",
    "        \n",
    "        print('class {0}, score: {1:.2f}'.format(all_classes[cl],score))\n",
    "        print('box coordinate x,y,w,h: {0}'.format(box))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image and check for possible matches\n",
    "def detect_image(image,yolo,all_classes):\n",
    "    pimage = process_image(image)\n",
    "    start = time.time()\n",
    "    \n",
    "    boxes,classes,scores = yolo.predict(pimage, image.shape)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print('time: {0:.2f}s'.format(end - start))\n",
    "#     If objects were detected, draw the boundary boxes\n",
    "    if boxes is not None:\n",
    "        draw(image,boxes,scores,classes,all_classes)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tracking\n",
    "def detect_video(video,yolo,all_classes):\n",
    "    video_path = os.path.join('videos','test',video)\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow('Detection',cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "#     Saving detected video\n",
    "    sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)), int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    \n",
    "    fourc = cv2.VideoWriter_fourcc(*'mpeg')\n",
    "    \n",
    "    vout = cv2.VideoWriter()\n",
    "    vout.open(os.path.join('videos','res',video), fourcc,20,sz,True)\n",
    "    \n",
    "    while True:\n",
    "        res, frame = camera.read()\n",
    "        \n",
    "        if not res:\n",
    "            break\n",
    "        \n",
    "        image = detect_image(frame,yolo,all_classes)\n",
    "        cv2.imshow('Detection',image)\n",
    "        vout.write(image)\n",
    "        \n",
    "        if cv2.waitKey(110) & 0xFF == 27:\n",
    "            break\n",
    "            \n",
    "    vout.release()\n",
    "    camera.release()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of YOLO algorithm with a certainty of 60% minimum\n",
    "yolo = YOLO(0.6,0.5)\n",
    "file = 'data/coco_classes.txt'\n",
    "all_classes = get_classes(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.60s\n",
      "class person, score: 0.96\n",
      "box coordinate x,y,w,h: [1022.0618248  1579.46288586  297.71628976  813.96505237]\n",
      "class car, score: 0.99\n",
      "box coordinate x,y,w,h: [1399.2279768  1571.51669264  609.26771164  364.11456764]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detecting images (street with cars and people)\n",
    "f = 'street.jpg'\n",
    "path = 'images/' + f\n",
    "image = cv2.imread(path)\n",
    "image = detect_image(image, yolo, all_classes)\n",
    "cv2.imwrite('images/res/' + f, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting on video (takes more time as evaluation is carried out frame by frame)\n",
    "# video = 'street.mp4'\n",
    "# detect_video(video, yolo, all_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
